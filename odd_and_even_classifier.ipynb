{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4086b288",
   "metadata": {},
   "source": [
    "# A classifier for odd and even\n",
    "\n",
    "This is weird, but it helps to emphasise the importance of data representation.\n",
    "\n",
    "I asked ChatGPT to write me some code for a decision tree to classify odd and even numbers. It obliged, creating a dataset of integers labelled as odd and even. I upped the number of samples in the dataset to 10k, but otherwise used the dataset-generating code directly. It gives a pandas dataframe with one column \"numbers\" and one column \"label\", where \"label\" is \"odd\" or \"even\". ChatGPT also gave me a fairly standard decision tree and said that it should get 100% accuracy because odd/even classification is a fairly easy task. But, of course, the decision tree failed utterly because a decision tree can't model odd/even with an integer data representation. It needs a binary representation.\n",
    "\n",
    "So I gave it a binary representation. The weird part is that, with a binary representation, single feature as a list or as a string, the model gets a fairly consistent level of accuracy, but it's not 100%. It depends on the dataset split, and might depend on the depth of the decision tree, too, I haven't tried yet. But why? What's the maths and is it complicated? The decision tree splits along \"nicer\" values - when you give it integers, the tree splits along fairly random values, but with a binary string, they *seem* to be nicer.\n",
    "\n",
    "Naturally splitting the single binary string into one feature for every digit (character) in the string gives a classifier with perfect accuracy - it just classifies based on the least significant digit, as it should. But ChatGPT didn't know to do this out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b1ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import export_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a736754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number label                               bin  \\\n",
      "0       1   Odd  00000000000000000000000000000001   \n",
      "1       3   Odd  00000000000000000000000000000011   \n",
      "2       5   Odd  00000000000000000000000000000101   \n",
      "3       7   Odd  00000000000000000000000000000111   \n",
      "4       9   Odd  00000000000000000000000000001001   \n",
      "5      11   Odd  00000000000000000000000000001011   \n",
      "6      13   Odd  00000000000000000000000000001101   \n",
      "7      15   Odd  00000000000000000000000000001111   \n",
      "8      17   Odd  00000000000000000000000000010001   \n",
      "9      19   Odd  00000000000000000000000000010011   \n",
      "\n",
      "                                            bin list char_1 char_2 char_3  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0      0      0   \n",
      "\n",
      "  char_4 char_5 char_6  ... char_23 char_24 char_25 char_26 char_27 char_28  \\\n",
      "0      0      0      0  ...       0       0       0       0       0       0   \n",
      "1      0      0      0  ...       0       0       0       0       0       0   \n",
      "2      0      0      0  ...       0       0       0       0       0       0   \n",
      "3      0      0      0  ...       0       0       0       0       0       0   \n",
      "4      0      0      0  ...       0       0       0       0       0       0   \n",
      "5      0      0      0  ...       0       0       0       0       0       0   \n",
      "6      0      0      0  ...       0       0       0       0       0       0   \n",
      "7      0      0      0  ...       0       0       0       0       0       0   \n",
      "8      0      0      0  ...       0       0       0       0       0       1   \n",
      "9      0      0      0  ...       0       0       0       0       0       1   \n",
      "\n",
      "  char_29 char_30 char_31 char_32  \n",
      "0       0       0       0       1  \n",
      "1       0       0       1       1  \n",
      "2       0       1       0       1  \n",
      "3       0       1       1       1  \n",
      "4       1       0       0       1  \n",
      "5       1       0       1       1  \n",
      "6       1       1       0       1  \n",
      "7       1       1       1       1  \n",
      "8       0       0       0       1  \n",
      "9       0       0       1       1  \n",
      "\n",
      "[10 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate some odds and evens\n",
    "odds = list(range(1, 10000, 2))   \n",
    "evens = list(range(0, 10000, 2)) \n",
    "\n",
    "# Create DataFrames with labels\n",
    "df_odds = pd.DataFrame({\"number\": odds, \"label\": \"Odd\"})\n",
    "df_evens = pd.DataFrame({\"number\": evens, \"label\": \"Even\"})\n",
    "\n",
    "# Combine them into one DataFrame\n",
    "df = pd.concat([df_odds, df_evens], ignore_index=True)\n",
    "bit_accuracy = 32\n",
    "\n",
    "def binarise(x):\n",
    "    return bin(x)[2:].zfill(bit_accuracy)\n",
    "\n",
    "def binarise_to_list(x):\n",
    "    s = bin(x)[2:].zfill(bit_accuracy)\n",
    "    return list(s)\n",
    "\n",
    "df[\"bin\"] = df[\"number\"].apply(np.vectorize(binarise))\n",
    "df[\"bin list\"] = df[\"number\"].apply(np.vectorize(binarise_to_list))\n",
    "df[\"bin\"] = df[\"bin\"].astype(str)\n",
    "\n",
    "## Putting the binary values into columns\n",
    "# Split strings into characters and expand into new columns\n",
    "df_chars = df[\"bin list\"].apply(list).apply(pd.Series)\n",
    "\n",
    "# Rename columns (optional: C1, C2, C3...)\n",
    "df_chars.columns = [f\"char_{i+1}\" for i in df_chars.columns]\n",
    "\n",
    "# Combine back with original DataFrame (if you want)\n",
    "df = pd.concat([df, df_chars], axis=1)\n",
    "\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f1dc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_representation = \"binary\"\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df[[\"number\"]]\n",
    "feature_names = [\"number\"]\n",
    "\n",
    "if data_representation == \"binary\":\n",
    "    X = df[[\"bin\"]]\n",
    "    feature_names = [\"bin\"]\n",
    "\n",
    "if data_representation == \"binary columns\":\n",
    "    bit_features = df.iloc[:, (0-bit_accuracy):]\n",
    "    X = bit_features\n",
    "    feature_names = df.columns[-32:]\n",
    "\n",
    "\n",
    "y = df[\"label\"].map({\"Odd\": 1, \"Even\": 0})  # safer as numeric\n",
    "\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a619cb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.31\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.40      0.37      1000\n",
      "           1       0.27      0.22      0.24      1000\n",
      "\n",
      "    accuracy                           0.31      2000\n",
      "   macro avg       0.30      0.31      0.30      2000\n",
      "weighted avg       0.30      0.31      0.30      2000\n",
      "\n",
      "|--- bin <= 10055.50\n",
      "|   |--- bin <= 0.50\n",
      "|   |   |--- class: 0\n",
      "|   |--- bin >  0.50\n",
      "|   |   |--- bin <= 10000.50\n",
      "|   |   |   |--- bin <= 5555.50\n",
      "|   |   |   |   |--- bin <= 100.50\n",
      "|   |   |   |   |   |--- bin <= 5.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- bin >  5.50\n",
      "|   |   |   |   |   |   |--- bin <= 10.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- bin >  10.50\n",
      "|   |   |   |   |   |   |   |--- bin <= 55.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- bin >  55.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- bin >  100.50\n",
      "|   |   |   |   |   |--- bin <= 1055.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- bin >  1055.50\n",
      "|   |   |   |   |   |   |--- bin <= 1100.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- bin >  1100.50\n",
      "|   |   |   |   |   |   |   |--- bin <= 1105.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- bin >  1105.50\n",
      "|   |   |   |   |   |   |   |   |--- bin <= 1110.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- bin >  1110.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- bin >  5555.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- bin >  10000.50\n",
      "|   |   |   |--- class: 1\n",
      "|--- bin >  10055.50\n",
      "|   |--- bin <= 100110.50\n",
      "|   |   |--- bin <= 100055.50\n",
      "|   |   |   |--- bin <= 100010.50\n",
      "|   |   |   |   |--- bin <= 11105.50\n",
      "|   |   |   |   |   |--- bin <= 11100.50\n",
      "|   |   |   |   |   |   |--- bin <= 10100.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- bin >  10100.50\n",
      "|   |   |   |   |   |   |   |--- bin <= 10105.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- bin >  10105.50\n",
      "|   |   |   |   |   |   |   |   |--- bin <= 11000.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- bin >  11000.50\n",
      "|   |   |   |   |   |   |   |   |   |--- bin <= 11005.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- bin >  11005.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin <= 11010.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin >  11010.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |--- bin >  11100.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- bin >  11105.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- bin >  100010.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- bin >  100055.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- bin >  100110.50\n",
      "|   |   |--- bin <= 100555.50\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- bin >  100555.50\n",
      "|   |   |   |--- bin <= 101000.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- bin >  101000.50\n",
      "|   |   |   |   |--- bin <= 101005.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- bin >  101005.50\n",
      "|   |   |   |   |   |--- bin <= 101010.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- bin >  101010.50\n",
      "|   |   |   |   |   |   |--- bin <= 101055.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- bin >  101055.50\n",
      "|   |   |   |   |   |   |   |--- bin <= 101100.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- bin >  101100.50\n",
      "|   |   |   |   |   |   |   |   |--- bin <= 110005.50\n",
      "|   |   |   |   |   |   |   |   |   |--- bin <= 101110.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin <= 101105.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin >  101105.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- bin >  101110.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- bin >  110005.50\n",
      "|   |   |   |   |   |   |   |   |   |--- bin <= 111010.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin <= 110105.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin >  110105.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- bin >  111010.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin <= 111055.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- bin >  111055.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualise\n",
    "tree_rules = export_text(clf, feature_names=feature_names)\n",
    "print(tree_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Train SVC\n",
    "clf = SVC(kernel=\"linear\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
